# ğŸ§© chunky

> *cut your codebase into bite-sized pieces for large language models to swallow whole... or choke on.*

**chunky** is a CLI tool written in Go for parsing, filtering, chunking, and formatting source code repositories into LLM-digestible chunks.  

Itâ€™s built for developers working on AI tooling, embeddings, summarization, search, or just staring into the abyss of their own spaghetti code.

---

## âœ¨ Features

- ğŸŒ€ **Recursive repo traversal** with `.chunkyignore` and glob filtering
- âœ‚ï¸ **Line-based chunking** with optional comment stripping
- ğŸ“ **Token estimation** (via heuristics)
- ğŸ“¦ **Formatter output**: plain text, Markdown, or JSON
- ğŸ“‹ **Preamble/postamble support** to wrap context
- ğŸ’… Easily extensible for more formats and chunking logic

---

## ğŸ› ï¸ Usage

```sh
chunky --repo /path/to/repo --out output_dir
```

### ğŸ´ CLI Flags

| Flag    | Type | Description |
| -------- | -------- | ------- |
| **--repo-url**  | string | Remote Git URL to clone (optional if --local-path is set)    |
| **--local-path** | string | Local path to an existing repo (optional if --repo-url is set)     |
| **--chunk-size** | int | Max tokens per chunk (approximate) â€” default: 3000     |
| **--format** | string | Output format: txt, md, or json â€” default: txt     |
| **--no-comments** | bool | Strip single- and multi-line comments before chunking     |
| **--include-globs** | string | Comma-separated glob patterns to include specific files (e.g. *.go,*.md)     |


â„¹ï¸ *You must provide either --repo-url or --local-path, or the void will protest.*

---

## ğŸ—‚ Project Structure
```txt
chunky/
â”œâ”€â”€ cmd/
â”‚   â””â”€â”€ chunky/              # main CLI entrypoint
â”œâ”€â”€ internal/
â”‚   â”œâ”€â”€ gitpuller/           # optional repo cloning/pulling
â”‚   â”œâ”€â”€ walker/              # file discovery & ignore filtering
â”‚   â”œâ”€â”€ chunker/             # line-based chunk splitting
â”‚   â”œâ”€â”€ formatter/           # txt / md / json output
â”‚   â”œâ”€â”€ preamble/            # pre/postamble injection
â”‚   â”œâ”€â”€ tokenizer/           # rough token estimators
â”‚   â””â”€â”€ flags/               # CLI flag parsing
â”œâ”€â”€ configs/                 # default .chunkyignore file
â”œâ”€â”€ scripts/                 # (optional) helper scripts
â”œâ”€â”€ go.mod
â””â”€â”€ README.md
```

---

## ğŸ§  Token Estimation
chunky uses simple heuristics:

- `~1.3 tokens` per word

or 

- `len(text) / 4` based on average token length

This isnâ€™t perfect â€” but itâ€™s good enough for quick splits.

Use proper tools like OpenAIâ€™s `tiktoken` or `transformers` if you need precision.

---

## ğŸŒ«ï¸ Example Output
```txt
ğŸ“„ repo-name/
â”œâ”€â”€ chunk_001.md
â”œâ”€â”€ chunk_002.md
â”œâ”€â”€ ...
```
Each chunk contains:
- File path metadata
- Source code (formatted based on flags)
- Markdown fences or JSON structure (if configured)

---

## ğŸ”¥ Example Use Cases

- Prepping code for GPT-4 or Claude-3 ingestion
- Repo embeddings for vector databases (e.g., Chroma, Pinecone)
- Context windows for agentic AI systems
- Training dataset prep
- Aesthetic pain

---

## ğŸ“„ .chunkyignore
just like `.gitignore`, this file defines what gets skipped.
supports globs, directories, files, etc. Ignore things that LLMs 
have no use for, such as `node_modules`.

```gitignore
node_modules/
build/
*.lock
.DS_Store
```

---

## ğŸ§ª Sample Run
```sh
chunky \
  --repo ./my-project \
  --out ./chunks \
  --strip-comments \
  --format md \
  --max-lines 80 \
  --preamble ./preamble.txt \
  --postamble ./postamble.txt
```

---

## ğŸ’€ Limitations
- Comment stripping is regex-based (and naive)
- Not token-aware â€” lines â‰  tokens
- Splits mid-function unless handled manually
- Only supports code-as-text; no AST parsing yet

---

## ğŸ’Œ Future Ideas
- Tree-sitter based syntax-aware splitting
- Function/class boundary chunking
- Chunk hashing + manifesting
- LLM preview/diffing tools
- Plugin system for alternate strategies

---

## ğŸ“œ License
MIT â€” free to fork, remix, and glitchify.

---

## ğŸŒ‘ Final Note
chunky doesnâ€™t pretend to understand your code.
it just carves it up, piece by piece, like memory loss.
the LLMs will try to make sense of it.
they may succeed. or hallucinate.

either way, the silence in the chunks is yours to fill.

---

appeal2heaven 2025